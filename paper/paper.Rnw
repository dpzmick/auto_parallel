\documentclass[10pt, letterpapper]{proc}
%\documentclass[12pt, letterpapper, titlepage]{article}
\usepackage{hyperref}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows}
\usetikzlibrary{positioning}

\usepackage{minted}
%\usemintedstyle{emacs}
\usemintedstyle{borland}

\usepackage[nottoc,numbib]{tocbibind}
\bibliographystyle{plain}

\def\mintcode#1{\mbox{\mintinline{clojure}{#1}}}
\def\code#1{\mbox{\texttt{#1}}}
\def\parlet{\code{parlet}}
\def\parexpr{\code{parexpr}}
\def\defparfun{\code{defparfun}}

\author{
    Zmick, David\\
    \texttt{zmick2@illinois.edu}
}

\title{Macros for straightforward parallelism in Clojure}

\begin{document}
<<include=FALSE>>=
source("../vis/basic_plot.R")
# data <- read.csv("../newnew.csv")
data <- read.csv("../data.csv")
@

\maketitle

% \tableofcontents
% \pagebreak

% question: Can macros be used to create interesting and useful parallelism
% tools for recursive functions in clojure.
\section{Introduction}

Clojure is a lisp--like language running on the Java Virtual Machine.\cite{Hickey2008}
The language's default immutable data structures and sophisticated Software Transactional Memory (STM) system make it well suited for parallel programming.\cite{Kraus2009}
Because Clojure runs on the Java Virtual Machine, Clojure developers can take advantage of existing cross--platform parallelism libraries, such as Java's excellent \code{ExecutorService} framework, to write parallel code.

% for example, writing a parallel map with atoms would be a big pain
However, taking advantage of Clojure's parallel potential is not entirely straightforward.
STM has proven to be very successful construct for concurrent programming\cite{Jones2007a}, but these constructs are often too low level to be of much use to developers whose central concerns are not parallelism\cite{Boehm2009}.

As a result, there are a variety of libraries designed to allow developers to take advantage of the parallelism potential in Clojure.
Clojure builtins such as pmap\footnotemark[1] and reducers\footnotemark[2] library provide data parallel sequence manipulation and transformation functions.
Third---party libraries like Tesser\footnotemark[3] and Claypoole\footnotemark[4] provide more data parallel APIs with slightly different goals than the builtin functions.
Developers have a good relationship with data parallel problems\cite{Okur2012a}, but Clojure's nature as a functional language with immutable structures also makes it possible to easily exploit control parallelism (also known as task parallelism\cite{Andradea, Rodr}).
An astute reader may observe that both Claypoole and the Clojure standard library include task parallel functions.
These will be discussed in the Section \ref{label:related_work}

\footnotetext[1]{\url{https://clojuredocs.org/clojure.core/pmap}}
\footnotetext[2]{\url{http://clojure.org/reference/reducers}}
\footnotetext[3]{\url{https://github.com/aphyr/tesser}}
\footnotetext[4]{\url{https://github.com/TheClimateCorporation/claypoole}}

Using Clojure's macro system, I have implemented a set of macros which allow developers to take advantage of Clojure's parallelism potential when their existing code is written such that parallelism is exposed through control flow.
I have shown that it is possible to attain reasonable degrees of parallelism with minimal code changes, with respect to serial code, using these macros.
The intended users of these macros are developers whose primary concern is not performance, but may benefit from a simple mechanism with which they can take advantage of the many cores in their machines.
Developers who are extremely concerned with performance and want a high degree of control should turn elsewhere (perhaps even to Java) to write their highly tuned code.

\section{Related Work} \label{label:related_work}
% only discuss task based parallelism in this section
Clojure has access to all of the JVM, so it has access to the Java \code{ForkJoinPool} library\cite{Lea2000}.
The \code{ForkJoinPool} library allows Java programmers to create lightweight, recursive tasks, then execute them on an efficient, work stealing, \code{ExecutionEngine}.
Users of a \code{ForkJoinPool} create a subclass of \code{RecursiveTask} to compute the value of some function.
Each of these tasks may create more \code{RecursiveTask}s, submit them to the \code{ForkJoinPool}, then wait for their subtasks to complete, without blocking the pool.
The execution engine for the \code{ForkJoinPool} is a thread pool.
Each thread maintains it's own queue of tasks to work on.
Whenever a thread runs out of tasks to work on, it steals tasks from other threads.
Work stealing has been used a scheduling mechanism is a variety of modern threading libraries and has been very successful \cite{Lea2000, Blumofe1994, Blumofe1995a}
Clojure programmers can use the \code{ForkJoinPool} from Clojure, but the interface isn't exactly programmer friendly.

Clojure also has some built in support for task parallelism via \code{future}\footnote{\url{https://clojuredocs.org/clojure.core/future}}.
Each call to future creates a thread to compute the result of a function call in the background.
When a user is ready to access a value, they can \code{deref} the future to get the computed value (\code{deref} will block until the value is computed).
For a user, \code{future}s initially seem like a fairly natural way to parallelize recursive functions.
Unfortunately, Futures only work well when a small number of tasks are created or when the tasks do a lot of blocking I/O.
Thread creation overhead is high, and people users must be careful not to create an excessive number of threads or create threads to do too little work.
Claypoole offers many improvements to the builtin Clojure \code{future}s, but it still creates a thread per task.
The work in this paper is conceptually similar, but the interface I have used differs dramatically from the \code{future}s interface.
My code also creates tasks for every thread, but these tasks are created on a Java \code{ForkJoinPool}, so the tasks are much more lightweight.

In Common Lisp, the \code{lparallel}\footnote{\url{https://lparallel.org/overview/}} library and macros are available.
The macros I have implemented are very similar to the macros \code{lparallel} provides, but, Common Lisp programming conventions are not as ideal for these kinds of macros.

\subsection{Other languages}
In other languages, frameworks like Cilk++\footnote{\url{https://www.cilkplus.org/}}, OpenMP\footnote{\url{http://openmp.org/wp/}}, Threading Building Blocks\footnote{\url{https://www.threadingbuildingblocks.org/}} all exist.
Some of these require compiler support and advanced dependence analysis to guarantee correctness.
These libraries all have great performance, but they can't be leveraged from Clojure.
The macros I've implemented are an attempt to bring some of the niceties of these libraries and compiler extensions to Clojure, without the need to compiler support or complicated dependence analysis.

\section{Mostly Pure Functions} \label{label:mostly_pure}
Before discussing the macros I've implemented, I need to loosely define a ``mostly pure'' function.
A mostly pure function is a thread---safe function with no side effects directly impacting the values of user-defined values, at the current level of abstraction.
Mostly pure functions can be reordered (or interleaved) without impacting the values of user variables, although the change may impact I/O behavior and output order of a program.
In some cases, the order of certain side effects may not matter to a programmer.
For example, it may not matter if we reorder \mintcode{(download file1)} and \mintcode{(download file2)} for a programmer writing a web scraper, but it may matter to a programmer writing a I/O constrained server.
When a programmer feels that it may be acceptable to change the order of, or interleave, calls to mostly pure functions (the call is ``portable''), we can reorder them subject to these constraints:

\begin{enumerate}
    \item A call to a mostly pure function $f$ in a block $B$ in a function's control flow graph can safely be moved to a block $P$ for which all paths in the graph though $P$ also go through $B$.
        Figure \ref{fig:move_mostly_pure} provides and example of this constraint.
    \item All of the arguments to the function are available at any block $P$ which is a candidate location for the function call.
        See Figure \ref{fig:move_mostly_pure_through_let} for an example.
\end{enumerate}

The first constraint is introduced so that we avoid network requests or print statements which never would have originally occurred along any given path of execution.
We do not want to allow reordering which introduces new computations or would result in unpredictable performance.
The second constraint ensures that we don't ever violate the most basic of correctness properties.
A more detailed algorithm for finding safe locations for portable mostly pure functions in Clojure code is discussed in Section \ref{label:mpure_algo}

\tikzstyle{goodnode} = [rectangle, draw=blue, text width=0.8\linewidth]
\tikzstyle{badnode}  = [rectangle, draw=none,  text width=0.8\linewidth]

\begin{figure}[h]
\centering
\begin{tikzpicture}[node distance=0.62cm,auto]
    \node[coordinate] (0) at (0.7,0) {};
    \node (start0)      [badnode]                                        {\mintcode{;; cannot move the call outside}};
    \node (start)       [badnode, below of=start0]                       {\mintcode{(if (pred? a b c ...)}};
    \node (iftruedo)    [goodnode, below of=start, right of=start]       {\mintcode{(do}};
    \node (iftruelet1)  [goodnode, below of=iftruedo, right of=iftruedo] {\mintcode{;; code that uses a, b, and/or c}};
    \node (iftruelet2)  [goodnode, below of=iftruelet1]                  {\mintcode{(foo a b c))}};
    \node (iffalse)     [badnode, below=2.8cm of 0]                      {\mintcode{(bar a b c))}};
\end{tikzpicture}
\caption{The call to the mostly pure function \code{foo} can only be moved to the boxed nodes}
\label{fig:move_mostly_pure}
\end{figure}

\begin{figure}[h]
\centering
\begin{tikzpicture}[node distance=0.61cm,auto]
    \node[coordinate] (0) at (1.0,0) {};
    \node (start)       [badnode]                                 {\mintcode{(do}};
    \node (a)           [badnode, below of=start, right of=start] {\mintcode{(let [a (bar 10)]}};
    \node (b)           [goodnode, below of=a, right of=a]        {\mintcode{;; code that uses a}};
    \node (c)           [goodnode, below of=b]                    {\mintcode{(let [b (bar a)]}};
    \node (d)           [goodnode, below of=c, right of=c]        {\mintcode{;; code that uses a and/or b}};
    \node (e)           [goodnode, below of=d]                    {\mintcode{(foo a)))}};
\end{tikzpicture}
\caption{The call to the mostly pure function \code{foo} can only be moved to the boxed nodes}
\label{fig:move_mostly_pure_through_let}
\end{figure}

Many Clojure functions fit this definition due to Clojure programming conventions and default immutable data structures.
In this paper, we rely on the judgment of the programmer to tell us when a mostly pure function is portable.

% A mostly pure function is similar to a \code{const} function in C++.
% \code{const} functions promise not to modify any members of the object on which they are called (unless the member was declared \code{mutable}), essentially promising that the object will not change, from the user of the object's perspective, when the \code{const} function is called.

\section{parlet}
The first of the parallel macros is called \parlet{}.
\parlet{} is a modified version of the Clojure \code{let} form.
The \parlet{} macro has exactly the same behavior as Clojure's \code{let}, but it evaluates all of its bindings in parallel.
For example, suppose I had some long running function \code{foo}.
I need to add the result of two calls to this function.
In Figure \ref{fig:parlet_basic}, we use \parlet{} to make two calls to \code{foo}, then add the results.

\begin{figure}[h]
\centering
\RecustomVerbatimEnvironment{Verbatim}{BVerbatim}{}
\begin{minted}{clojure}
(parlet
  [a (foo value1)
   b (foo value2)]
   ... ; some other code here
  (+ a b))
\end{minted}
\caption{Example of a parlet form}
\label{fig:parlet_basic}
\end{figure}

In this example, the expressions \mintcode{(foo value1)} and \mintcode{(foo value2)} are both evaluated as \code{ForkJoinTask}s in a \code{ForkJoinPool}\cite{Lea2000}.
The calls to \code{foo} are both forked immediately, then we attempt to evaluate the body of the \parlet{}.
This means that the code in the body of the \code{let} which does not depend on the computations of \code{a} and \code{b} can execute without delay.
Additionally, since the \code{ForkJoinPool} is designed for recursive workloads, tasks which are currently executing can create new tasks, submit them to the pool, then wait for the task to complete, without blocking execution.
This means that nested \parlet{} forms (Figure \ref{fig:parlet_noblock}) will not block each other.

\begin{figure}[h]
\centering
\RecustomVerbatimEnvironment{Verbatim}{BVerbatim}{}
\begin{minted}{clojure}
(parlet
  [a (foo 100)]
  ;; some other code not using a
  (parlet
    [b (foo 200)]
    (+ a b)))
\end{minted}
\caption{Nested parlet forms}
\label{fig:parlet_noblock}
\end{figure}

Code like this may not arise when the code is human generated, but it may arise when the code is generated by another macro.
We will see some examples of this later.

\subsection{Dependencies}
The \parlet{} macro also supports simple dependency detection.
Clojure \code{let} forms can use names defined previously in the let, and the bindings are evaluated from first to last.

\begin{figure}[h]
\centering
\RecustomVerbatimEnvironment{Verbatim}{BVerbatim}{}
\begin{minted}{clojure}
(parlet
  [a 1
   b (+ 1 a)]
  a)
\end{minted}
\caption{A parlet containing a dependency}
\label{fig:parlet_dep}
\end{figure}

Without the \parlet{}, the let form in Figure \ref{fig:parlet_dep} would evaluate to 2.
If we plan on evaluating each binding in parallel, we can't allow the bindings to have dependencies.
So, the \parlet{} macro looks through the bindings in the macro to determine if any of them depend on any of the names defined previously in the macro.
If there are any, the macro will halt the compiler and report an error to the user.

\subsection{Correctness}
This transformation is only safe when \code{foo} (and more generally, any function call in the bindings) is a mostly pure function.
If the programmer chooses to use a \parlet{} form, we assume that the functions called in the bindings are mostly pure.
This simple dependency check, as well as the programmers promise that all function called are mostly pure Clojure code, allow us to ensure correct parallelism with this macro.

% \section{parexpr}

% The \parexpr{} macro breaks down expressions and (aggressively) evaluates them in parallel.
% Suppose again that I had a long running function \code{foo} which I wanted to call twice, and add the results.
% The code in Figure \ref{fig:parexpr} will make both of the long running calls to \code{foo} in parallel.
% The \parexpr{} macro crawls the expression and expands it into multiple nested \parlet{} forms, filling each \parlet{} with as many evaluations as it can.

% \begin{figure}[h]
% \centering
% \RecustomVerbatimEnvironment{Verbatim}{BVerbatim}{}
% \begin{minted}{clojure}
% (parexp (+ (foo value1) (foo value2)))
% \end{minted}
% \caption{Example using parexpr to evaluate long running functions}
% \label{fig:parexpr}
% \end{figure}

\section{defparfun}

\defparfun{} allows a programmer to parallelize calls to a recursive function.
The \defparfun{} macro supports a granularity argument, allowing the programmer to specify when they would like to stop creating additional parallel tasks.
The macro emits the expression provided for granularity inside of an \code{if} statement at the top of the function, so the programmer can use any arbitrary condition, including conditions dependent on the functions arguments, to decide when to stop spawning new tasks.

For an example see Figure \ref{fig:fib_code}.
This defines a parallel Fibonacci function, which will only execute in parallel when the value of it's argument is greater than $35$.

\begin{figure}[h]
\RecustomVerbatimEnvironment{Verbatim}{BVerbatim}{}
\centering
\begin{minted}{clojure}
(defparfun fib [n] (< n 35)
  (if (or (= 0 n) (= 1 n))
    1
    (+
     (fib (- n 1))
     (fib (- n 2)))))
\end{minted}
\caption{Fibonacci function with \defparfun{} added}
\label{fig:fib_code}
\end{figure}

\subsection{Implementation} \label{label:mpure_algo}
To do implement this macro, I first expand all of the \code{let} expressions in the function so that every \code{let} only has a single binding.
Then, the syntax tree is crawled, finding every recursive function call.
Every recursive call is replaced by a newly introduced variable.
At the termination of each recursive call, the bindings introduced in the subexpression are returned.
Once all of the subexpressions are evaluated, the algorithms decides if it must emit a \code{let} form for any of the bindings the subexpressions introduced.
If the expression in question is an \code{if} statement, a let statement is introduced for the \code{true} branch and on the \code{false} branch, each containing all of the bindings introduced by the subexpressions for each branch.
If the statement is a let statement, only the bindings which depend on the binding introduced by the let statement are emitted (following the let of course).
This operation effectively pushed the evaluation of the function all as far ``up'' in the function as it can, following the constraints described in Section \ref{label:mostly_pure}.

After this transformation, it is possible to replace the \code{let} forms which bind the function results to their values with \parlet{} forms providing the same bindings.
The introduction of the \parlet{} form introduces parallelism, so each recursive call will execute in the \code{ForkJoin} pool, in parallel.

Because the transformation does not violate any of the properties defined for mostly pure functions, this transformation is safe when the function being declared as a \code{parfun} is mostly pure.

\begin{figure}[h]
\RecustomVerbatimEnvironment{Verbatim}{BVerbatim}{}
\centering
\begin{minted}{clojure}
(defn fib [n]
 ;; granularity check
 (if (< n 35)
  (if (or (= 0 n) (= 1 n))
   1
   (+ (fib (- n 1))
      (fib (- n 2))))

  ;; recursive case
  (if (or (= 0 n) (= 1 n))
   1
   (parlet [expr17300 (fib (- n 1))
            expr17301 (fib (- n 2))]
    (+ expr17300 expr17301)))))
\end{minted}
\caption{Transformed function}
\label{fig:parfun_result}
\end{figure}

\section{Benchmarking}
To run benchmarks, I used Google's Cloud Compute virtual machines.
For each trial, a virtual machine was created.
Each virtual machine had either $1$, $2$, $4$, or $6$ cores and $6$ gigabytes of RAM.
First, the serial version of the code was run, then, on the same machine, the parallel version of the code was run.
After both trials finished running, the data was copied back to my local machine and the virtual machine was destroyed.
For every pair of serial/parallel executions, the speedup was computed.
These per--machine speedups are used to generate the plots shown.

To workaround the difficulties JVM benchmarking introduces, the Criterium\footnote{\url{https://github.com/hugoduncan/criterium}} library was used for Clojure code and the Caliper\footnote{\url{https://github.com/google/caliper}} library was used with Java code.
The JVM does not expose a mechanism to control the total number of threads it creates (including garbage collection threads).
Because each benchmark was run on it's own virtual machine with a constrained number of cores, the number of threads the JVM could create was controlled.

\subsection{Fibonacci}

\begin{figure}[h]
\RecustomVerbatimEnvironment{Verbatim}{BVerbatim}{}
\centering
\begin{minted}{clojure}
(defun fib [n]
  (if (or (= 0 n) (= 1 n))
    1
    (+
     (fib (- n 1))
     (fib (- n 2)))))
\end{minted}
\caption{Serial Fibonacci function}
\label{fig:fib_serial}
\end{figure}

First we will look at the classical recursive Fibonacci example.
Figure \ref{fig:fib_serial} shows the serial benchmark code; \ref{fig:fib_code} shows the code parallel benchmark code.
In Figure \ref{fig:fibparfun} the results from many trials of this code running $1$, $2$, $4$, and $6$ cores.
Each benchmark computes \mintcode{(fib 39)}.
We see that we get about a 3x speedup with $6$ cores.
This speedup isn't quite what we would hope to see, but, as can be seen in Figure \ref{fig:javafib}, the handwritten Java \code{ForkJoinPool} implementation gets about the same speedup with $6$ cores on these virtual machines.
Previous \code{ForkJoinPool} benchmarks have shown much better speedups for similar code\cite{Lea2000}, so I suspect that the virtual machine configuration is somewhat responsible for the discrepancy in results.

<<fibparfun, fig.pos="H", fig.cap="Fibonacci Clojure (defparfun) Performance", echo=F, out.width='\\linewidth', fig.align='center'>>=
cljfib <- plot_means_error_for_benchmark(data, "fib", "parfun")
@

<<javafib, fig.pos="H", fig.cap="Fibonacci Java Performance", echo=F, out.width='\\linewidth', fig.align='center'>>=
jfib <- plot_means_error_for_benchmark(data, "fib", "fj")
@

The large variance we see in the Clojure benchmarks is somewhat disturbing, especially since it does not show up in the Java results.
Since it does not appear in the Java benchmarks, it is not a result of variable performance in the Google Cloud Platform virtual machines.
In Figure \ref{fig:fib_sd} I show the standard deviation of the mean runtime for the serial and parallel Clojure Fibonacci functions, along with their Java counterparts.
Notice that the Java results do not have nearly as high deviations from mean runtime.
While I cannot completely explain the variability, it seems to be caused by the increased pressure Clojure's function implementation and the \code{ForkJoinPool} wrapper tasks places on the JVM garbage collector.
Every Clojure function is an \code{Object} created following the Clojure \code{IFn} interface\footnote{\url{http://clojure.org/reference/special_forms\#fn}}.
When running on the \code{ForkJoinPool}, each function is further wrapped in a \code{RecursiveTask} object, causing additional allocations.
This effectively moves the stack for the recursive function to the heap.
There is so upside to this; it eliminates the stack depth limit (which is an issue in Clojure because Clojure cannot implement tail call optimization), the large number of allocations creates a large amount garbage collector pressure.
The garbage collector behaves somewhat non---deterministically, so I believe this is the explanation for the large variation in runtime for the serial and recursive Fibonacci code.
We can avoid excessive task creation by controlling the granularity of parallelism, to an extent.
The Fibonacci example highlights this problem because the function call overhead greatly exceeds the amount of work each call is doing.
We will see an example for which this is not the case in Section \ref{label:id3_bench}.

<<fib_sd, fig.pos="H", fig.cap=" ", echo=F, out.width='\\linewidth', fig.align='center'>>=
fib <- data[data$spec.name %like% "fib.big",]

important <- c("cores", "mean.runtime")

clj_serial <- ddply(fib[fib$spec.name %like% "serial",important], "cores", colwise(sd))
clj_parfun <- ddply(fib[fib$spec.name %like% "parfun",important], "cores", colwise(sd))

java_serial <-ddply(data[data$spec.name %like% "serial_java", important], "cores", colwise(sd))
java_par    <-ddply(data[data$spec.name %like% "fj_java", important], "cores", colwise(sd))

# d <- merge(clj_serial, clj_parfun, "cores", suffixes = c("serial", "parfun"))
d <- join_all(list(clj_serial, clj_parfun, java_serial, java_par), by="cores")

nnames <- c("Clojure serial", "Clojure parallel w/ defparfun", "java serial", "java fork/join")
names(d)[2] <- nnames[1]
names(d)[3] <- nnames[2]
names(d)[4] <- nnames[3]
names(d)[5] <- nnames[4]

barplot(t(as.matrix(d[,nnames])), beside=TRUE, names=d$cores, legend=nnames,
        main = "Fibonacci standard deviations", xlab="cores", ylab="mean runtime standard deviation")
@

\subsection{ID3} \label{label:id3_bench}
I also implemented a simple ID3\footnote{\url{https://en.wikipedia.org/wiki/ID3_algorithm}} classifier in Clojure.
The code is bit longer, so it is not included in this paper, but it can be found on this project's Github page\footnote{\url{https://github.com/dpzmick/auto_parallel}}.

For each benchmark, a random 1,000 element dataset was created.
Each element of the dataset was given 100 random features.
The \code{ID3} algorithm implementation ran until it was out of attributes to pivot on.

The \code{ID3} code does much more work in each function call, so the additional overhead created by Clojure's function implementation does not seem to impact the results as much as it does in the Fibonacci benchmark.

Figure \ref{fig:id3parfun} shows that we get the 3x speedup we expect on these virtual machines with the \code{ID3} algorithm.

<<id3parfun, fig.pos="H", fig.cap="id3 Clojure (defparfun) Performance", echo=F, out.width='\\linewidth', fig.align='center'>>=
id3 <- plot_means_error_for_benchmark(data, "id3", "parfun")
@

\section{Conclusions and Future Work}
The Clojure macros I've implemented perform transformation which can speedup Clojure code to a degree which matches the speedups attained using handwritten Java code, running on the same hardware.
Parallelism is difficult, and automatic parallelism is possible\cite{Banerjee1993}, but these techniques are complicated and often do not get the desired results and the research community has begun to feel the need for explicit parallelism in programs.\cite{Arvind2010}
Languages like Clojure are well suited for this parallelism and techniques like mine can easily be implemented.
In a language with a strong STM system and immutable structures, such transformations are easy to reason about, making it much simpler for programmers to implement explicitly parallel programs.

Macros of this style do not inhibit the programmers ability to use the other mechanisms implemented in the language, although interoperability with them could be improved.
For example, one of the tests which was not discussed in this paper involved using the STM system from within a function declared with \defparfun{}.
Benchmarks on this code behaved correctly and performance improved as expected.
However, if a programmer attempted to use a \code{pmap} or \code{future} inside of a \defparfun{} or \parlet{}, the two systems would create separate thread pools and the number of created threads would be large, possibly causing poor performance.
There are also a variety of other useful macros in lparallel\footnote{\url{https://lparallel.org/}} that may be useful to implement in Clojure and would complement the macros I've implemented in this project.

It would also be useful to use profiling tools and implement static analysis tools which would detect potential locations for these macros.
These tools could be used by developers to look for potential opportunities for parallelism, and they could be used to demonstrate the claim that many Clojure programs may benefit from use of these macros.

\bibliography{/home/dpzmick/Documents/Bibtex/senior-thesis.bib}

\end{document}
